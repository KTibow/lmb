{"name":"blacktooth","multimodal":true,"context":"The anonymous model \"blacktooth\" is generating significant positive buzz on the LM Arena leaderboard. Users are consistently reporting \"good output\" and generally describe it as \"very good.\"\n\nA common sentiment is that blacktooth is a notable improvement over existing models. Many users assert it's \"definitely better than 2.5 pro,\" with some even suggesting it \"equals if not exceeds\" it. Comparisons to \"Kingfall\" are frequent, with opinions varying on which is superior; some place Kingfall above blacktooth, while others argue blacktooth performs comparably or better, especially noting that Kingfall sometimes \"struggled to perform on par with 2.5-pro.\" A key characteristic highlighted is that blacktooth achieves correct answers with \"less thinking\" compared to Kingfall, which is seen as a positive for efficiency.\n\nRegarding its identity, the prevailing hypothesis is that blacktooth is either the anticipated \"2.5 Ultra\" model or at least a larger model than 2.5 Pro. This theory is supported by observations of internal model names, which suggest a larger model size. Users describe blacktooth as feeling \"related to but still separate from 2.5 pro,\" implying it's not merely a \"juiced up\" version but a distinct, potentially new, substantive model."}
{"name":"folsom-exp-v1.5","multimodal":false,"context":"There's some buzz around **folsom-exp-v1.5**, a new model reportedly from Amazon. Users are curious about its nature, with one describing it as \"pretty solid.\" However, initial testing has been mixed; some users encountered errors on follow-up questions, hindering proper evaluation. It's also noted for thinking too long on simple questions, leading to speculation that it might be designed for more complex tasks rather than quick, straightforward queries."}
{"name":"magistral-medium-2506","multimodal":false,"context":"*none*"}
{"name":"prowlridge","multimodal":true,"context":"There's a notable buzz surrounding **prowlridge**, a new model recently introduced into LM Arena's Battle mode.\n\nInitially, several users claimed to \"confirm\" that prowlridge is **\"2.5 Flash Lite.\"** However, this identification quickly became a point of debate. One user highlighted that the internal naming convention for prowlridge (and models like Kingfall and Blacktooth) ends in 'l' (e.g., 'v3p1l'), while \"2.5 Pro\" ends in 'm', suggesting a distinction related to model size. This has led to speculation that prowlridge might not be \"2.5 Pro\" or even \"2.5 Flash Lite\" as initially thought, adding to the mystery of its true identity.\n\nIn terms of performance, early impressions suggest it's **\"technically a bit worse than Kingfall but pretty similar,\"** though this assessment has been met with some disagreement. The community is actively curious about its capabilities, with many asking \"is prowlridge good?\" The general sentiment indicates a high level of interest and speculation about this new contender on the leaderboard."}
{"name":"stephen","multimodal":false,"context":"The arrival of an anonymous model named **`stephen`** on the LM Arena leaderboard sparked considerable discussion. Users quickly noted its peculiar tendency to **respond in Chinese**, even when prompted in other languages, leading to initial confusion and speculation about its origin.\n\nEarly theories widely circulated that `stephen` might be the new **DeepSeek R1** or even a pre-release of **Grok-3.5**. However, these were largely debunked by users who pointed out that the official DeepSeek R1 was already on the arena under its proper name, and `stephen` performed significantly worse, particularly in coding tasks. Some also speculated it could be an undisclosed version of **Qwen** or simply a \"random small Chinese model.\"\n\nThe most compelling and widely accepted theory, later confirmed by a linked X post, identifies `stephen` as a model from **StepFun**, a Chinese AI company. This connection, based on the similarity of the names and the model's behavior, helped clarify the initial confusion with DeepSeek.\n\nIn terms of performance, the general consensus among users was that `stephen` is **\"not a good model, at all,\"** often grouped with other \"really bad\" anonymous models on the arena (with the exception of `goldmane`). It was also frequently mentioned in discussions about models that error out or stop responding mid-generation. Despite its initial reception, a **`stephen-v2`** and a **`stephen-vision`** model later appeared in the arena's battle and vision modes, respectively."}
{"name":"stephen-v2","multimodal":false,"context":"There's a notable buzz surrounding the introduction of **`stephen-v2`** as a new model in LM Arena's Battle mode. Its arrival has coincided with a discussion about the platform potentially supporting video models, specifically image-to-video generation.\n\nUsers expressed surprise and excitement, with comments like \"What the hell ? Is now lmarena has video models...?\" and \"WHAT, where is that\". While one user clarified that the current setup might be a \"smart workaround\" for benchmarking, the general sentiment is one of curiosity and anticipation for the future of video model testing on LM Arena. There's a clear desire for full text-to-video benchmarking, with one user quickly realizing they can already submit their own prompts for testing."}
{"name":"stephen-vision","multimodal":true,"context":"A new model, `stephen-vision`, has just been announced as entering the Vision Arena. Beyond its initial introduction, there's no further discussion or buzz about its performance or capabilities in this chat snippet."}
{"name":"X-preview","multimodal":false,"context":"The \"X-preview\" model has recently appeared on the LM Arena leaderboard, generating some buzz and confusion among users.\n\nPrimarily, X-preview is identified as **Baidu's Wenxin X1 (ERNIE X1)**. It initially responds in Chinese unprompted, though subsequent interactions are in English. Despite its self-identification, some users have reported a bug where it occasionally identifies as an OpenAI model, with its responses sometimes resembling GPT-4.1-mini.\n\nIn terms of performance, the general sentiment is that X-preview is **underwhelming**. Users have described it as \"nothing to write home about\" and even that it \"sucks,\" noting it doesn't perform or feel like Grok.\n\nThe model is also associated with **technical issues**, particularly errors when handling complex queries. These errors, which can affect both models in a battle, are suspected to be related to max token limits or timeouts. There was some initial confusion in the community, with a few users mistakenly thinking X-preview might be Grok 3.5, but this was quickly clarified."}
