{"name":"flamesong","multimodal":true,"context":"Flamesong is a new model that has generated considerable buzz on the LM Arena leaderboard. It's widely believed to be a new iteration in the Google Flash line, with some users speculating it could be \"Flash 3.0\" or \"Gemini Flash Plus.\"\n\nIn terms of performance, Flamesong is generally described as \"decent\" and \"good,\" with capabilities \"similar to 2.5flash.\" Users note it's \"better than flash\" but \"less good than pro,\" positioning it closer to Pro in overall quality. Its speed is a point of discussion; while some find it \"kinda fast\" or even \"faster than pro,\" others observe its token per second rate is similar to 2.5 Pro or Flash. It's considered strong, but \"not as good as Google's best.\"\n\nInitially, there was confusion and frustration regarding its availability, with users reporting it \"doesn't work\" or wasn't accessible on \"webdev.\" However, it has since \"arrived on webdev,\" which was met with excitement. Now, some users report frequently encountering Flamesong in their rounds, occasionally to the point of frustration."}
{"name":"folsom-06192025-1","multimodal":false,"context":"*none*"}
{"name":"kraken-250610-1","multimodal":false,"context":"A new model, **`kraken-250610-1`**, has recently appeared in the LM Arena. Initial discussions revolved around its origin, with some speculating it might be another Chinese model. However, it was later identified as an \"Amazon reasoning model.\" There's also a general query about its performance, with someone asking, \"Good?\""}
{"name":"kraken-250610-2","multimodal":false,"context":"*none*"}
{"name":"step-1o-turbo-202506","multimodal":true,"context":"The only mention of \"step-1o-turbo-202506\" in this chat log is its announcement by `davidszd` as a \"New model.\" There's no further discussion or \"buzz\" about its capabilities or performance within this snippet."}
{"name":"stephen","multimodal":false,"context":"The anonymous model `stephen` has generated considerable discussion on the LM Arena leaderboard, primarily due to its perceived Chinese origin and varying performance.\n\nInitially, users like `nofrizzsomerizz` noted `stephen`'s tendency to **answer in Chinese**, leading to speculation about its identity â€“ perhaps a version of R1, Qwen, or even DeepSeek. However, `pedanticallyprofound` quickly dismissed these theories, stating it's \"not\" those models but rather \"random small Chinese models.\"\n\nThe most prominent theory regarding its origin, put forth by `kiri49` and later seemingly confirmed by `davidszd` via an X.com link, is that `stephen` is from **StepFun**, a Chinese AI company. Another user, `wild1436`, also suggested ByteDance.\n\nDespite the intrigue around its identity, `stephen`'s **performance has been largely criticized**. `pedanticallyprofound` bluntly called it \"not a good model, at all\" and \"really bad,\" advising users there's \"no reason to pay attention to them\" compared to other anonymous models like 'goldmane'. Users have also reported it, along with other Chinese models, experiencing **errors** or hitting token limits on complex queries.\n\nThe model has seen new iterations, with `stephen-vision` appearing in the Vision Arena and `stephen-v2` in Battle mode, indicating continued development or testing despite the mixed reception."}
{"name":"stephen-v2","multimodal":false,"context":"There's a notable buzz surrounding the introduction of **`stephen-v2`** as a new model in LM Arena's Battle mode. Its arrival has coincided with a discussion about the platform potentially supporting video models, specifically image-to-video generation.\n\nUsers expressed surprise and excitement, with comments like \"What the hell ? Is now lmarena has video models...?\" and \"WHAT, where is that\". While one user clarified that the current setup might be a \"smart workaround\" for benchmarking, the general sentiment is one of curiosity and anticipation for the future of video model testing on LM Arena. There's a clear desire for full text-to-video benchmarking, with one user quickly realizing they can already submit their own prompts for testing."}
{"name":"stephen-vision","multimodal":true,"context":"A new model, `stephen-vision`, has just been announced as entering the Vision Arena. Beyond its initial introduction, there's no further discussion or buzz about its performance or capabilities in this chat snippet."}
{"name":"stonebloom","multimodal":true,"context":"Stonebloom recently arrived on the LM Arena leaderboard and WebDev, generating significant discussion among users.\n\nIts initial rollout was plagued with issues, with many users reporting blank or non-responsive generations, particularly on complex prompts in WebDev. This led to frustration and calls for fixes, with `m30wster` noting \"1 in 4 webdev gens are empty.\" However, these issues were reportedly resolved, with `m30wster` later confirming \"stonebloom works now on webdev.\"\n\nOnce stable, its performance became a hot topic. Users frequently compared it to other anonymous Google models like **Kingfall** and **Blacktooth**, as well as **Gemini 2.5 Pro** and **Flash**. Early sentiment was mixed, with some users like `chacaaca` placing it below Kingfall and Blacktooth (`kingfall > blacktooth > 0605 > stonebloom`), while others, like `chacaaca` again, noted its capabilities were \"similar to 2.5flash\" or even potentially \"better than 2.5pro.\"\n\nOn specific benchmarks, results varied. For **SVG generation**, particularly complex 'Terminator' prompts, `peasantry1833` and `davidszd` found Kingfall superior, citing Stonebloom's \"sampling seed is still so low\" for consistent good results. However, `m30wster` praised Stonebloom for getting a \"realistic new homepage for about.x.com\" SVG right, calling it the \"best output\" from any model for that prompt. In a **math problem** (ribbon calculation), `m30wster` demonstrated Stonebloom giving an incorrect answer compared to a new, unnamed Google model. For a **knowledge recall task** (One Piece chapter title), `kskombu` found Stonebloom performed well \"most of the time,\" better than Flash but less consistently than 2.5 Pro.\n\nA notable positive change observed by `ourobaros` was Stonebloom's reduced \"sycophancy\" and more \"straight to the point\" responses, a welcome shift from previous models. There was debate about its nature: `kskombu` speculated it might be a \"2.5-pro-lite,\" but `peasantry1833` clarified, citing \"big b\" (Craig bench), that Stonebloom is *not* distilled and shares the \"same param count as kf,\" suggesting it's a **checkpoint** of the same larger model as Kingfall and Blacktooth, rather than a smaller, distilled version.\n\nOverall, the buzz around Stonebloom is one of cautious optimism mixed with ongoing evaluation. While it initially struggled with stability and some benchmarks, its improved directness and occasional strong performance on specific tasks keep users engaged in testing its true capabilities and its place in the evolving Google model lineup."}
{"name":"X-preview","multimodal":false,"context":"The \"X-preview\" model is generating some buzz on the LM Arena. While it's currently in the battle section and not yet on the main leaderboard, users have noted a few interesting characteristics.\n\nInitially, there was some confusion, with a user mistakenly identifying it as **Grok 3.5**, which was quickly corrected. It has been observed to occasionally identify itself as an **OpenAI model**, with its responses strikingly resembling those of **GPT-4.1-mini**.\n\nHowever, X-preview is also associated with a specific type of error: when facing complex queries, it (along with some Qwen and Deepseek models) can trigger a battle-ending error, possibly due to max token limits or timeouts.\n\nThe most definitive information comes from the model itself, which, when prompted, identifies as **Baidu's Wenxin X1 (ERNIE X1)**. It states it was developed independently by Baidu using its PaddlePaddle deep learning framework, leveraging Baidu's AI expertise, and aims to provide a professional, secure, and contextually appropriate intelligent interaction experience in Chinese."}