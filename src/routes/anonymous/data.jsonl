{"name":"flamesong","multimodal":true,"context":"Flamesong is a new model that's been generating buzz on the LM Arena leaderboard. It's widely speculated to be a new iteration in the \"Google Flash line,\" with some users calling it \"Flash 3.0\" or \"Gemini Flash Plus.\"\n\nIn terms of performance, Flamesong is generally described as \"pretty decent\" and \"good,\" with capabilities similar to or better than Flash 2.5, though most agree it's \"less good than Pro\" and not on par with \"Google's best.\" Its speed is a key talking point, with many perceiving it as \"kinda fast,\" and some even claiming it \"think[s] faster than Pro,\" though there are conflicting reports on its exact token-per-second rate compared to other models.\n\nInitially, users reported issues with it not being live or working on Aistudio, and it wasn't immediately available or correctly listed in the metadata for the webdev arena. However, it has since arrived on webdev, with some users now frequently encountering it in their rounds. While one user humorously claimed it \"solved all my relationship issues,\" another found it \"not so good,\" indicating a mixed but generally positive reception."}
{"name":"kraken-250610-1","multimodal":false,"context":"A new model, **`kraken-250610-1`**, has recently appeared in the LM Arena. Initial discussions revolved around its origin, with some speculating it might be another Chinese model. However, it was later identified as an \"Amazon reasoning model.\" There's also a general query about its performance, with someone asking, \"Good?\""}
{"name":"step-1o-turbo-202506","multimodal":true,"context":"A new model, **\"step-1o-turbo-202506\"**, was briefly noted in the LM Arena leaderboard discussion. However, the provided chat log contains no further \"buzz\" or details regarding its features or performance, as the conversation quickly shifted to other topics."}
{"name":"stephen-v2","multimodal":false,"context":"There's a notable buzz surrounding the introduction of **`stephen-v2`** as a new model in LM Arena's Battle mode. Its arrival has coincided with a discussion about the platform potentially supporting video models, specifically image-to-video generation.\n\nUsers expressed surprise and excitement, with comments like \"What the hell ? Is now lmarena has video models...?\" and \"WHAT, where is that\". While one user clarified that the current setup might be a \"smart workaround\" for benchmarking, the general sentiment is one of curiosity and anticipation for the future of video model testing on LM Arena. There's a clear desire for full text-to-video benchmarking, with one user quickly realizing they can already submit their own prompts for testing."}
{"name":"stephen-vision","multimodal":true,"context":"A new model, `stephen-vision`, has just been announced as entering the Vision Arena. Beyond its initial introduction, there's no further discussion or buzz about its performance or capabilities in this chat snippet."}
{"name":"steve","multimodal":false,"context":"The anonymous model \"Steve\" on the LM Arena leaderboard has sparked significant discussion and speculation among users.\n\nInitially, there was strong buzz and even \"confirmation\" from some users that Steve was a new model from Deepseek. However, other theories also circulated, with some suggesting it could be a Bytedance model (given past \"Stephen\" models) or even Grok 4.\n\nOpinions on Steve's performance are mixed. Some users reported that Steve \"almost got all the answers right\" and found it \"isn't so bad,\" while others were less impressed, noting it was \"way behind v3 and R1\" for certain tasks like creating a Discord clone, and \"didn't pass this test.\" One user even described it as \"fuckin ass\" based on recent tests, though another observed it might employ \"hybrid reasoning.\"\n\nAdding to the confusion, a user directly prompted Steve, and the model consistently identified itself as \"Amazon Titan,\" contradicting the earlier Deepseek claims. This self-identification, coupled with observations that it \"variably answers when asked who made it,\" has only deepened the mystery surrounding Steve's true origin."}
{"name":"stonebloom","multimodal":true,"context":"The arrival of **stonebloom** on the LM Arena, initially on \"webdev\" and then the main arena, generated significant buzz, though its rollout was plagued by early issues with blank responses and timeouts, particularly on the webdev interface. Users reported difficulty getting it to respond consistently, with some needing many attempts.\n\nInitial reactions to stonebloom's performance have been **mixed**. While some users, particularly for specific tasks like generating SVGs, found it \"insane for web designing\" and capable of producing \"best output\" for certain prompts (e.g., a realistic homepage for about.x.com), others reported it as \"not good\" and struggling with complex prompts or \"lethal scenarios.\" One user noted it was the \"only model I've tried to get this right\" for certain knowledge-based queries, and it performed decently on quizzes, showing \"stonebloom-level knowledge.\" However, it notably failed a specific ribbon calculation problem multiple times where another anonymous model succeeded.\n\nComparisons to other models are a central theme of the discussion:\n\n*   **Vs. Kingfall & Blacktooth:** Many users, including prominent testers, generally place **Kingfall** above stonebloom, and often **Blacktooth** above stonebloom as well, especially in \"conversation analysis tasks.\" There's a sentiment that stonebloom \"feels generally like it's only got worse since kingfall.\"\n*   **Vs. 2.5 Pro:** Stonebloom is often described as having capabilities \"similar to 2.5flash\" or a \"2.5-pro-lite\" version, though this \"distilled\" theory is debated, with some claiming it has the \"same param count as kf\" and is \"not distilled.\" While 2.5 Pro consistently answered a specific knowledge question correctly, stonebloom was mostly correct but occasionally erred.\n*   **Thinking & Speed:** A recurring observation is that stonebloom \"thinks less\" than 2.5 Pro, Kingfall, and Blacktooth, and is generally slower than Flash models, roughly on par with Blacktooth.\n\nSpeculation abounds regarding stonebloom's nature: some believe it's a new iteration of 2.5 Pro, while others suggest that Kingfall, Blacktooth, and stonebloom are all \"checkpoints of the same model,\" larger than 2.5 Pro, undergoing refinement. There's also a positive note on its writing style, with one user praising it for being \"less sycophancy and straight to the point\" compared to 2.5 Pro.\n\nOverall, stonebloom's reception is characterized by a blend of excitement for a new model, frustration over initial technical glitches and perceived performance regressions compared to its predecessors like Kingfall, and ongoing debate about its place in the evolving landscape of anonymous models."}
{"name":"wolfstride","multimodal":true,"context":"\n**Wolfstride: The New Mystery Model on the Block**\n\n\"Wolfstride\" has emerged as a new, anonymous model on the LM Arena leaderboard, sparking considerable curiosity and discussion among users. Initially identified as a \"new Google model\" by some, it quickly became one of the \"mystery models\" that users are keen to test.\n\n**Key Buzz Points:**\n\n*   **High Demand for Access:** Many users are asking \"How do I use wolfstride?\" and \"Where can I test Wolfstride?\", indicating a strong desire to get hands-on with the new model.\n*   **Impressive Knowledge & Quiz Performance:**\n    *   One user reported \"one shotted this on wolfstride,\" suggesting strong performance on a specific task.\n    *   It's noted to have \"stonebloom-level knowledge.\"\n    *   Crucially, it scored an impressive **7/9** on a user-created quiz designed to determine model level (Flash/Pro/Ultra). This score significantly outperforms models like 2.5-pro/goldmane (which scored 5.5) and most other models (below zero), suggesting it's a high-tier contender in terms of knowledge.\n*   **Potential Reasoning Limitations:** Despite its strong knowledge base, some users observe that \"wolfstride & stonebloom think much less than 2.5 pro,\" hinting at a possible weakness in complex reasoning compared to other top models.\n*   **Overall Sentiment:** The general sentiment is one of excitement and anticipation. Users are actively trying to get instances of wolfstride to test it further and understand its full capabilities, with a conditional positive outlook (\"provided wolfstride is good\")."}
{"name":"X-preview","multimodal":false,"context":"The \"X-preview\" model is generating some buzz on the LM Arena. While it's currently in the battle section and not yet on the main leaderboard, users have noted a few interesting characteristics.\n\nInitially, there was some confusion, with a user mistakenly identifying it as **Grok 3.5**, which was quickly corrected. It has been observed to occasionally identify itself as an **OpenAI model**, with its responses strikingly resembling those of **GPT-4.1-mini**.\n\nHowever, X-preview is also associated with a specific type of error: when facing complex queries, it (along with some Qwen and Deepseek models) can trigger a battle-ending error, possibly due to max token limits or timeouts.\n\nThe most definitive information comes from the model itself, which, when prompted, identifies as **Baidu's Wenxin X1 (ERNIE X1)**. It states it was developed independently by Baidu using its PaddlePaddle deep learning framework, leveraging Baidu's AI expertise, and aims to provide a professional, secure, and contextually appropriate intelligent interaction experience in Chinese."}
